{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-02 20:55:33,950 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-02 20:55:34,342 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "2020-02-02 20:55:34,862 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-02 20:55:35,233 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-02-02 20:55:35,234 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-02-02 20:55:35,265 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 20:55:35,269 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-02 20:55:35,283 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-02 20:55:35,384 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-02 20:55:35,392 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:35,403 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-02 20:55:35,450 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 20:55:35,513 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 20:55:35,557 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 20:55:35,678 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local572091546_0001\n",
      "2020-02-02 20:55:35,954 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676935778/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:35,970 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676935778/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:35,970 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676935778/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:35,970 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp255450571/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580676935778/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:35,982 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676935779/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:35,993 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676935779/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:35,993 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676935779/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:35,993 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp1868794715/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580676935779/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:35,994 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676935780/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:36,006 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676935780/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:36,006 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676935780/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:36,006 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1107651170/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580676935780/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:36,007 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676935781/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:36,021 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676935781/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:36,021 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676935781/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:36,021 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-143489056/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580676935781/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:36,086 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676935778/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:36,087 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676935779/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:36,087 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676935780/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:36,087 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676935781/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:36,093 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 20:55:36,099 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 20:55:36,134 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 20:55:36,138 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:36,138 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:36,139 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 20:55:36,193 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 20:55:36,207 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local572091546_0001_m_000000_0\n",
      "2020-02-02 20:55:36,253 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:36,253 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:36,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:36,288 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 632\n",
      "Input split[0]:\n",
      "   Length = 632\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 20:55:36,308 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:36,309 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:36,361 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 20:55:36,361 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local572091546_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:36,371 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 20:55:36,372 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local572091546_0001_m_000000_0 is allowed to commit now\n",
      "2020-02-02 20:55:36,375 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local572091546_0001_m_000000_0' to file:/tmp/temp181107271/tmp398497160/_temporary/0/task_local572091546_0001_m_000000\n",
      "2020-02-02 20:55:36,376 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 20:55:36,376 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local572091546_0001_m_000000_0' done.\n",
      "2020-02-02 20:55:36,384 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local572091546_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5801912\n",
      "\t\tFILE: Number of bytes written=12065367\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tInput split bytes=398\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=236453888\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 20:55:36,385 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local572091546_0001_m_000000_0\n",
      "2020-02-02 20:55:36,385 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 20:55:41,127 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:41,145 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:41,145 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-02-02 20:55:41,145 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 20:55:41,147 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:41,257 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:41,267 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 20:55:41,357 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 20:55:41,359 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 20:55:41,372 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1434037830_0002\n",
      "2020-02-02 20:55:41,542 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676941399/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:41,549 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676941399/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:41,549 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676941399/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:41,550 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-642015149/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580676941399/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:41,551 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676941400/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:41,561 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676941400/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:41,561 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676941400/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:41,561 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1776299861/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580676941400/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:41,563 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676941401/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:41,574 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676941401/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:41,575 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676941401/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:41,575 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1358958549/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580676941401/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:41,576 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676941402/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:41,584 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676941402/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:41,585 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676941402/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:41,585 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1321247312/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580676941402/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:41,637 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676941399/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:41,637 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676941400/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:41,637 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676941401/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:41,637 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676941402/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:41,638 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 20:55:41,639 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 20:55:41,646 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 20:55:41,646 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 20:55:41,647 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:41,647 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:41,647 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 20:55:41,652 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 20:55:41,653 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1434037830_0002_m_000000_0\n",
      "2020-02-02 20:55:41,689 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:41,690 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:41,690 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:41,694 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 259\n",
      "Input split[0]:\n",
      "   Length = 259\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 20:55:41,758 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 20:55:41,759 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 20:55:41,759 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 20:55:41,759 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 20:55:41,759 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 20:55:41,765 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 20:55:41,812 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 20:55:41,812 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 20:55:41,812 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 20:55:41,812 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 608; bufvoid = 104857600\n",
      "2020-02-02 20:55:41,812 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2020-02-02 20:55:41,821 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 20:55:41,826 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1434037830_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:41,831 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 20:55:41,831 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1434037830_0002_m_000000_0' done.\n",
      "2020-02-02 20:55:41,833 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1434037830_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603445\n",
      "\t\tFILE: Number of bytes written=24150123\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=608\n",
      "\t\tMap output materialized bytes=650\n",
      "\t\tInput split bytes=376\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=18\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=341835776\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 20:55:41,834 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1434037830_0002_m_000000_0\n",
      "2020-02-02 20:55:41,834 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 20:55:41,838 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 20:55:41,838 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1434037830_0002_r_000000_0\n",
      "2020-02-02 20:55:41,862 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:41,862 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:41,865 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:41,870 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6e234ba8\n",
      "2020-02-02 20:55:41,895 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 20:55:41,910 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1434037830_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 20:55:41,953 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1434037830_0002_m_000000_0 decomp: 646 len: 650 to MEMORY\n",
      "2020-02-02 20:55:41,959 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 646 bytes from map-output for attempt_local1434037830_0002_m_000000_0\n",
      "2020-02-02 20:55:41,961 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 646, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->646\n",
      "2020-02-02 20:55:41,965 [Readahead Thread #0] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-02-02 20:55:41,966 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 20:55:41,971 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:41,971 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 20:55:41,983 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 20:55:41,984 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 621 bytes\n",
      "2020-02-02 20:55:41,987 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 646 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 20:55:41,988 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 650 bytes from disk\n",
      "2020-02-02 20:55:41,989 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 20:55:41,989 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 20:55:41,990 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 621 bytes\n",
      "2020-02-02 20:55:41,990 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:42,006 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:42,006 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:42,008 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-02-02 20:55:42,049 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1434037830_0002_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:42,054 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:42,054 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1434037830_0002_r_000000_0 is allowed to commit now\n",
      "2020-02-02 20:55:42,057 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1434037830_0002_r_000000_0' to file:/tmp/temp181107271/tmp1394008573/_temporary/0/task_local1434037830_0002_r_000000\n",
      "2020-02-02 20:55:42,059 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 20:55:42,059 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1434037830_0002_r_000000_0' done.\n",
      "2020-02-02 20:55:42,062 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1434037830_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11604777\n",
      "\t\tFILE: Number of bytes written=24150841\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=650\n",
      "\t\tReduce input records=18\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=18\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=341835776\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 20:55:42,063 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1434037830_0002_r_000000_0\n",
      "2020-02-02 20:55:42,064 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 20:55:46,793 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:46,795 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:46,797 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:46,846 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:46,853 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 20:55:46,924 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 20:55:46,926 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 20:55:46,936 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1037708887_0003\n",
      "2020-02-02 20:55:47,089 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676946964/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:47,097 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676946964/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:47,098 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676946964/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:47,098 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-530618547/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580676946964/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:47,099 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676946965/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:47,108 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676946965/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:47,109 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676946965/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:47,109 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1559847689/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580676946965/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:47,110 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676946966/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:47,117 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676946966/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:47,118 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676946966/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:47,118 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-878661135/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580676946966/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:47,122 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676946967/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:47,127 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676946967/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:47,128 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676946967/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:47,128 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1866685793/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580676946967/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:47,129 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676946968/tmp1394008573 <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pigsample_121245483_1580676946830\n",
      "2020-02-02 20:55:47,138 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676946968/tmp1394008573 /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pigsample_121245483_1580676946830' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pigsample_121245483_1580676946830': Protocol error\n",
      "\n",
      "2020-02-02 20:55:47,138 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676946968/tmp1394008573 <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pigsample_121245483_1580676946830\n",
      "2020-02-02 20:55:47,138 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp1394008573 as file:/tmp/hadoop-root/mapred/local/1580676946968/tmp1394008573\n",
      "2020-02-02 20:55:47,185 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676946964/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:47,185 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676946965/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:47,185 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676946966/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:47,185 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676946967/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:47,186 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 20:55:47,186 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 20:55:47,193 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 20:55:47,193 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 20:55:47,193 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:47,193 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:47,194 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 20:55:47,201 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 20:55:47,201 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1037708887_0003_m_000000_0\n",
      "2020-02-02 20:55:47,214 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:47,214 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:47,215 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:47,227 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 259\n",
      "Input split[0]:\n",
      "   Length = 259\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 20:55:47,256 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 20:55:47,256 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 20:55:47,256 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 20:55:47,256 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 20:55:47,256 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 20:55:47,263 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 20:55:47,270 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 20:55:47,271 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 20:55:47,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 20:55:47,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 295; bufvoid = 104857600\n",
      "2020-02-02 20:55:47,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214328(104857312); length = 69/6553600\n",
      "2020-02-02 20:55:47,302 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 20:55:47,303 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1037708887_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:47,312 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 20:55:47,312 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1037708887_0003_m_000000_0' done.\n",
      "2020-02-02 20:55:47,315 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1037708887_0003_m_000000_0: Counters: 18\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406394\n",
      "\t\tFILE: Number of bytes written=36241891\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=18\n",
      "\t\tMap output records=18\n",
      "\t\tMap output bytes=295\n",
      "\t\tMap output materialized bytes=105\n",
      "\t\tInput split bytes=376\n",
      "\t\tCombine input records=18\n",
      "\t\tCombine output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=426246144\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 20:55:47,316 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1037708887_0003_m_000000_0\n",
      "2020-02-02 20:55:47,316 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 20:55:47,317 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 20:55:47,323 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1037708887_0003_r_000000_0\n",
      "2020-02-02 20:55:47,350 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:47,351 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:47,352 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:47,352 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6b2bd851\n",
      "2020-02-02 20:55:47,354 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 20:55:47,362 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1037708887_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 20:55:47,371 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1037708887_0003_m_000000_0 decomp: 101 len: 105 to MEMORY\n",
      "2020-02-02 20:55:47,373 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 101 bytes from map-output for attempt_local1037708887_0003_m_000000_0\n",
      "2020-02-02 20:55:47,373 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->101\n",
      "2020-02-02 20:55:47,374 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 20:55:47,375 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:47,376 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 20:55:47,378 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 20:55:47,378 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-02 20:55:47,380 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 101 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 20:55:47,380 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 105 bytes from disk\n",
      "2020-02-02 20:55:47,380 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 20:55:47,380 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 20:55:47,385 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-02 20:55:47,386 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:47,394 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:47,395 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:47,401 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1037708887_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:47,405 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:47,405 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1037708887_0003_r_000000_0 is allowed to commit now\n",
      "2020-02-02 20:55:47,407 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1037708887_0003_r_000000_0' to file:/tmp/temp181107271/tmp-864560239/_temporary/0/task_local1037708887_0003_r_000000\n",
      "2020-02-02 20:55:47,409 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 20:55:47,409 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1037708887_0003_r_000000_0' done.\n",
      "2020-02-02 20:55:47,409 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1037708887_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406636\n",
      "\t\tFILE: Number of bytes written=36242087\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=105\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=426246144\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 20:55:47,410 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1037708887_0003_r_000000_0\n",
      "2020-02-02 20:55:47,410 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 20:55:52,367 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:52,370 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:52,372 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:52,413 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:52,419 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 20:55:52,472 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 20:55:52,474 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 20:55:52,490 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local726596984_0004\n",
      "2020-02-02 20:55:52,635 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676952529/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:52,638 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676952529/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:52,639 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676952529/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:52,639 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp1379246126/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580676952529/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:52,640 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676952530/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:52,644 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676952530/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:52,644 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676952530/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:52,644 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp1611277070/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580676952530/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:52,645 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676952531/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:52,649 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676952531/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:52,649 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676952531/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:52,649 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp-1418080386/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580676952531/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:52,653 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580676952532/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:52,658 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580676952532/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 20:55:52,658 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580676952532/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:52,658 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp181107271/tmp1268303946/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580676952532/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:52,707 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676952529/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 20:55:52,707 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676952530/automaton-1.11-8.jar\n",
      "2020-02-02 20:55:52,707 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676952531/antlr-runtime-3.4.jar\n",
      "2020-02-02 20:55:52,707 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580676952532/joda-time-2.9.3.jar\n",
      "2020-02-02 20:55:52,708 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 20:55:52,708 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 20:55:52,719 [Thread-130] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-02 20:55:52,720 [Thread-130] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 20:55:52,721 [Thread-130] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 20:55:52,721 [Thread-130] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:52,721 [Thread-130] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:52,721 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 20:55:52,736 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 20:55:52,737 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local726596984_0004_m_000000_0\n",
      "2020-02-02 20:55:52,752 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:52,752 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:52,755 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:52,757 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 79\n",
      "Input split[0]:\n",
      "   Length = 79\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 20:55:52,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 20:55:52,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 20:55:52,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 20:55:52,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 20:55:52,785 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 20:55:52,786 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 20:55:52,790 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 20:55:52,790 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 20:55:52,790 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 20:55:52,790 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 89; bufvoid = 104857600\n",
      "2020-02-02 20:55:52,790 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600\n",
      "2020-02-02 20:55:52,791 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 20:55:52,792 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local726596984_0004_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:52,795 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 20:55:52,796 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local726596984_0004_m_000000_0' done.\n",
      "2020-02-02 20:55:52,796 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local726596984_0004_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23207988\n",
      "\t\tFILE: Number of bytes written=48318697\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=5\n",
      "\t\tMap output records=5\n",
      "\t\tMap output bytes=89\n",
      "\t\tMap output materialized bytes=105\n",
      "\t\tInput split bytes=377\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=5\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=432537600\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 20:55:52,796 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local726596984_0004_m_000000_0\n",
      "2020-02-02 20:55:52,797 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 20:55:52,798 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 20:55:52,800 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local726596984_0004_r_000000_0\n",
      "2020-02-02 20:55:52,811 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:52,811 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:52,813 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 20:55:52,813 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@63f6beb1\n",
      "2020-02-02 20:55:52,814 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 20:55:52,821 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local726596984_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 20:55:52,829 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#3 about to shuffle output of map attempt_local726596984_0004_m_000000_0 decomp: 101 len: 105 to MEMORY\n",
      "2020-02-02 20:55:52,830 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 101 bytes from map-output for attempt_local726596984_0004_m_000000_0\n",
      "2020-02-02 20:55:52,830 [localfetcher#3] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 101, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->101\n",
      "2020-02-02 20:55:52,831 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 20:55:52,831 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:52,832 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 20:55:52,834 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 20:55:52,834 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-02 20:55:52,839 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 101 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 20:55:52,839 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 105 bytes from disk\n",
      "2020-02-02 20:55:52,839 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 20:55:52,839 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 20:55:52,840 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 83 bytes\n",
      "2020-02-02 20:55:52,840 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:52,842 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 20:55:52,842 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 20:55:52,908 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local726596984_0004_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 20:55:52,923 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 20:55:52,924 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local726596984_0004_r_000000_0 is allowed to commit now\n",
      "2020-02-02 20:55:52,950 [pool-14-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local726596984_0004_r_000000_0' to file:/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q10-10/output/_temporary/0/task_local726596984_0004_r_000000\n",
      "2020-02-02 20:55:52,951 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 20:55:52,951 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local726596984_0004_r_000000_0' done.\n",
      "2020-02-02 20:55:52,951 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local726596984_0004_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=23208230\n",
      "\t\tFILE: Number of bytes written=48318863\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=105\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=5\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=432537600\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 20:55:52,951 [pool-14-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local726596984_0004_r_000000_0\n",
      "2020-02-02 20:55:52,952 [Thread-130] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 20:55:57,932 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,934 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,935 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,949 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,950 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,950 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,955 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,956 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,956 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,959 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,959 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,960 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,963 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,963 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 20:55:57,964 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
