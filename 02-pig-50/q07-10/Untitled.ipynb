{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-02 19:20:25,172 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-02 19:20:26,043 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "2020-02-02 19:20:27,294 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-02 19:20:28,247 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-02-02 19:20:28,249 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-02-02 19:20:28,323 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 19:20:28,333 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-02 19:20:28,366 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-02 19:20:28,600 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-02 19:20:28,616 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:28,658 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-02 19:20:28,768 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 19:20:28,962 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 19:20:29,047 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 19:20:29,261 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1447404710_0001\n",
      "2020-02-02 19:20:29,932 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671229484/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:29,963 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671229484/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:29,963 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671229484/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:29,964 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp891319854/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580671229484/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:30,049 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671229485/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:30,066 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671229485/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:30,066 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671229485/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:30,067 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp-362899173/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580671229485/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:30,069 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671229486/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:30,078 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671229486/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:30,078 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671229486/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:30,079 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp-1571147998/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580671229486/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:30,081 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671229487/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:30,100 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671229487/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:30,100 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671229487/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:30,102 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp-335879420/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580671229487/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:30,229 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671229484/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:30,229 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671229485/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:30,229 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671229486/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:30,229 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671229487/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:30,249 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 19:20:30,280 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 19:20:30,350 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 19:20:30,357 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:30,357 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:30,359 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 19:20:30,488 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 19:20:30,490 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1447404710_0001_m_000000_0\n",
      "2020-02-02 19:20:30,613 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:30,614 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:30,681 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 19:20:30,695 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 1780\n",
      "Input split[0]:\n",
      "   Length = 1780\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 19:20:30,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:30,738 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:30,892 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 19:20:30,893 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1447404710_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 19:20:30,921 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 19:20:30,927 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1447404710_0001_m_000000_0 is allowed to commit now\n",
      "2020-02-02 19:20:30,936 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1447404710_0001_m_000000_0' to file:/tmp/temp-784858623/tmp-807484002/_temporary/0/task_local1447404710_0001_m_000000\n",
      "2020-02-02 19:20:30,937 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 19:20:30,938 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1447404710_0001_m_000000_0' done.\n",
      "2020-02-02 19:20:30,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1447404710_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5803060\n",
      "\t\tFILE: Number of bytes written=12067916\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tInput split bytes=398\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=170917888\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 19:20:30,950 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1447404710_0001_m_000000_0\n",
      "2020-02-02 19:20:30,951 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 19:20:35,320 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:35,356 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:35,357 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-02-02 19:20:35,357 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 19:20:35,360 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:35,577 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:35,597 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 19:20:35,736 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 19:20:35,745 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 19:20:35,780 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1980029663_0002\n",
      "2020-02-02 19:20:36,069 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671235876/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:36,085 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671235876/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:36,086 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671235876/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:36,086 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp-810746900/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580671235876/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:36,089 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671235877/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:36,104 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671235877/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:36,104 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671235877/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:36,104 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp-1688799141/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580671235877/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:36,108 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671235878/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:36,117 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671235878/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:36,117 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671235878/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:36,118 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp-1440288734/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580671235878/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:36,120 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671235879/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:36,130 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671235879/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:36,131 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671235879/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:36,131 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp629504158/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580671235879/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:36,219 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671235876/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:36,220 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671235877/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:36,221 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671235878/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:36,221 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671235879/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:36,225 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 19:20:36,234 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 19:20:36,257 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 19:20:36,257 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 19:20:36,258 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:36,258 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:36,259 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 19:20:36,268 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 19:20:36,269 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1980029663_0002_m_000000_0\n",
      "2020-02-02 19:20:36,319 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:36,319 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:36,324 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 19:20:36,331 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 480\n",
      "Input split[0]:\n",
      "   Length = 480\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 19:20:36,435 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 19:20:36,435 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 19:20:36,436 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 19:20:36,437 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 19:20:36,437 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 19:20:36,461 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 19:20:36,548 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 19:20:36,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 19:20:36,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 19:20:36,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 1160; bufvoid = 104857600\n",
      "2020-02-02 19:20:36,551 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600\n",
      "2020-02-02 19:20:36,587 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 19:20:36,594 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1980029663_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 19:20:36,604 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 19:20:36,605 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1980029663_0002_m_000000_0' done.\n",
      "2020-02-02 19:20:36,606 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1980029663_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11604816\n",
      "\t\tFILE: Number of bytes written=24153406\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tMap output bytes=1160\n",
      "\t\tMap output materialized bytes=1246\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=40\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=301465600\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 19:20:36,607 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1980029663_0002_m_000000_0\n",
      "2020-02-02 19:20:36,607 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 19:20:36,615 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 19:20:36,616 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1980029663_0002_r_000000_0\n",
      "2020-02-02 19:20:36,697 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:36,697 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:36,701 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 19:20:36,710 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@187b4f59\n",
      "2020-02-02 19:20:36,746 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 19:20:36,765 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1980029663_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 19:20:36,860 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local1980029663_0002_m_000000_0 decomp: 1242 len: 1246 to MEMORY\n",
      "2020-02-02 19:20:36,873 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 1242 bytes from map-output for attempt_local1980029663_0002_m_000000_0\n",
      "2020-02-02 19:20:36,882 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 1242, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->1242\n",
      "2020-02-02 19:20:36,887 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 19:20:36,890 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 19:20:36,890 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 19:20:36,909 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 19:20:36,910 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1222 bytes\n",
      "2020-02-02 19:20:36,915 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 1242 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 19:20:36,916 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 1246 bytes from disk\n",
      "2020-02-02 19:20:36,919 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 19:20:36,919 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 19:20:36,925 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 1222 bytes\n",
      "2020-02-02 19:20:36,926 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 19:20:36,936 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:36,936 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:36,939 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-02-02 19:20:37,006 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1980029663_0002_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 19:20:37,017 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 19:20:37,017 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1980029663_0002_r_000000_0 is allowed to commit now\n",
      "2020-02-02 19:20:37,024 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1980029663_0002_r_000000_0' to file:/tmp/temp-784858623/tmp1361465662/_temporary/0/task_local1980029663_0002_r_000000\n",
      "2020-02-02 19:20:37,031 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 19:20:37,032 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1980029663_0002_r_000000_0' done.\n",
      "2020-02-02 19:20:37,040 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1980029663_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11607340\n",
      "\t\tFILE: Number of bytes written=24154720\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=1246\n",
      "\t\tReduce input records=40\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=40\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=301465600\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 19:20:37,042 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1980029663_0002_r_000000_0\n",
      "2020-02-02 19:20:37,043 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 19:20:41,264 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:41,268 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:41,270 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:41,387 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:41,412 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 19:20:41,528 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 19:20:41,534 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 19:20:41,555 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1445261368_0003\n",
      "2020-02-02 19:20:41,858 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671241641/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:41,865 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671241641/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:41,866 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671241641/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:41,866 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp1869174391/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580671241641/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:41,870 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671241642/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:41,881 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671241642/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:41,881 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671241642/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:41,881 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp1476357195/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580671241642/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:41,884 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671241643/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:41,893 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671241643/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:41,893 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671241643/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:41,894 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp226740787/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580671241643/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:41,895 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671241644/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:41,912 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671241644/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 19:20:41,912 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671241644/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:41,912 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp68182853/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580671241644/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:41,915 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580671241645/tmp1361465662 <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pigsample_1710491273_1580671241361\n",
      "2020-02-02 19:20:41,923 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580671241645/tmp1361465662 /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pigsample_1710491273_1580671241361' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pigsample_1710491273_1580671241361': Protocol error\n",
      "\n",
      "2020-02-02 19:20:41,923 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580671241645/tmp1361465662 <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/pigsample_1710491273_1580671241361\n",
      "2020-02-02 19:20:41,923 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-784858623/tmp1361465662 as file:/tmp/hadoop-root/mapred/local/1580671241645/tmp1361465662\n",
      "2020-02-02 19:20:42,041 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671241641/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 19:20:42,041 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671241642/automaton-1.11-8.jar\n",
      "2020-02-02 19:20:42,041 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671241643/antlr-runtime-3.4.jar\n",
      "2020-02-02 19:20:42,041 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580671241644/joda-time-2.9.3.jar\n",
      "2020-02-02 19:20:42,042 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 19:20:42,042 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 19:20:42,059 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-02 19:20:42,062 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 19:20:42,062 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 19:20:42,063 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:42,064 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:42,064 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 19:20:42,113 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 19:20:42,114 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1445261368_0003_m_000000_0\n",
      "2020-02-02 19:20:42,151 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:42,151 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:42,159 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 19:20:42,169 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 480\n",
      "Input split[0]:\n",
      "   Length = 480\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 19:20:42,227 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 19:20:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 19:20:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 19:20:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 19:20:42,228 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 19:20:42,243 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 19:20:42,268 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 19:20:42,271 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 19:20:42,271 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 19:20:42,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 560; bufvoid = 104857600\n",
      "2020-02-02 19:20:42,272 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214240(104856960); length = 157/6553600\n",
      "2020-02-02 19:20:42,278 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 19:20:42,290 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1445261368_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 19:20:42,310 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 19:20:42,310 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1445261368_0003_m_000000_0' done.\n",
      "2020-02-02 19:20:42,317 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1445261368_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17409180\n",
      "\t\tFILE: Number of bytes written=36234857\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=40\n",
      "\t\tMap output records=40\n",
      "\t\tMap output bytes=560\n",
      "\t\tMap output materialized bytes=646\n",
      "\t\tInput split bytes=378\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=40\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=319291392\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 19:20:42,322 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1445261368_0003_m_000000_0\n",
      "2020-02-02 19:20:42,322 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 19:20:42,324 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 19:20:42,326 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1445261368_0003_r_000000_0\n",
      "2020-02-02 19:20:42,356 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:42,357 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:42,360 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 19:20:42,361 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1fca9a06\n",
      "2020-02-02 19:20:42,363 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 19:20:42,375 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1445261368_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 19:20:42,382 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1445261368_0003_m_000000_0 decomp: 642 len: 646 to MEMORY\n",
      "2020-02-02 19:20:42,386 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 642 bytes from map-output for attempt_local1445261368_0003_m_000000_0\n",
      "2020-02-02 19:20:42,390 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 642, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->642\n",
      "2020-02-02 19:20:42,391 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 19:20:42,393 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 19:20:42,393 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 19:20:42,397 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 19:20:42,397 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 629 bytes\n",
      "2020-02-02 19:20:42,401 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 642 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 19:20:42,402 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 646 bytes from disk\n",
      "2020-02-02 19:20:42,402 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 19:20:42,402 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 19:20:42,403 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 629 bytes\n",
      "2020-02-02 19:20:42,404 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 19:20:42,408 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 19:20:42,408 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 19:20:42,547 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1445261368_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 19:20:42,565 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 19:20:42,566 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1445261368_0003_r_000000_0 is allowed to commit now\n",
      "2020-02-02 19:20:42,608 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1445261368_0003_r_000000_0' to file:/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q07-10/output/_temporary/0/task_local1445261368_0003_r_000000\n",
      "2020-02-02 19:20:42,610 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 19:20:42,610 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1445261368_0003_r_000000_0' done.\n",
      "2020-02-02 19:20:42,611 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1445261368_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17410504\n",
      "\t\tFILE: Number of bytes written=36235755\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=29\n",
      "\t\tReduce shuffle bytes=646\n",
      "\t\tReduce input records=40\n",
      "\t\tReduce output records=40\n",
      "\t\tSpilled Records=40\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=319291392\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 19:20:42,611 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1445261368_0003_r_000000_0\n",
      "2020-02-02 19:20:42,612 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 19:20:47,062 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,068 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,074 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,095 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,098 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,100 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,119 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,124 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,128 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,140 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,142 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 19:20:47,144 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
