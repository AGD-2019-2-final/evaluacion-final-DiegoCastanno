{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-02 17:47:13,586 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-02-02 17:47:14,764 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "2020-02-02 17:47:16,086 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-02 17:47:17,029 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-02-02 17:47:17,032 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-02-02 17:47:17,128 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 17:47:17,137 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-02 17:47:17,144 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 17:47:17,182 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-02 17:47:17,495 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-02 17:47:17,521 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:17,571 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-02 17:47:17,762 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 17:47:18,036 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 17:47:18,122 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 17:47:18,329 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local173023042_0001\n",
      "2020-02-02 17:47:19,033 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665638561/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:19,079 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665638561/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:19,080 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665638561/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:19,081 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp-498514842/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580665638561/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:19,150 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665638562/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:19,179 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665638562/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:19,183 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665638562/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:19,183 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp2063383996/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580665638562/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:19,186 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665638563/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:19,214 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665638563/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:19,214 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665638563/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:19,215 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp1012846670/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580665638563/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:19,219 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665638564/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:19,229 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665638564/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:19,230 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665638564/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:19,230 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp-1573218261/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580665638564/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:19,357 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665638561/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:19,358 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665638562/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:19,359 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665638563/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:19,359 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665638564/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:19,384 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 17:47:19,395 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 17:47:19,490 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 17:47:19,490 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 17:47:19,508 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:19,508 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:19,509 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 17:47:19,688 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 17:47:19,691 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local173023042_0001_m_000000_0\n",
      "2020-02-02 17:47:19,871 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:19,872 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:19,926 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 17:47:19,948 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 2271958\n",
      "Input split[0]:\n",
      "   Length = 2271958\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 17:47:20,049 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 17:47:20,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 17:47:20,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 17:47:20,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 17:47:20,050 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 17:47:20,059 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 17:47:20,166 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 17:47:20,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 17:47:20,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 17:47:20,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 231; bufvoid = 104857600\n",
      "2020-02-02 17:47:20,167 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "2020-02-02 17:47:20,202 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 17:47:20,217 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local173023042_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 17:47:20,244 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 17:47:20,244 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local173023042_0001_m_000000_0' done.\n",
      "2020-02-02 17:47:20,261 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local173023042_0001_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5805399\n",
      "\t\tFILE: Number of bytes written=12074744\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=231\n",
      "\t\tMap output materialized bytes=257\n",
      "\t\tInput split bytes=420\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=237502464\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 17:47:20,264 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local173023042_0001_m_000000_0\n",
      "2020-02-02 17:47:20,265 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 17:47:20,276 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 17:47:20,278 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local173023042_0001_r_000000_0\n",
      "2020-02-02 17:47:20,341 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:20,341 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:20,348 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 17:47:20,361 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@a9cbe8\n",
      "2020-02-02 17:47:20,416 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 17:47:20,439 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local173023042_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 17:47:20,545 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local173023042_0001_m_000000_0 decomp: 253 len: 257 to MEMORY\n",
      "2020-02-02 17:47:20,554 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 253 bytes from map-output for attempt_local173023042_0001_m_000000_0\n",
      "2020-02-02 17:47:20,558 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 253, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->253\n",
      "2020-02-02 17:47:20,566 [Readahead Thread #0] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-02-02 17:47:20,578 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 17:47:20,586 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 17:47:20,587 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 17:47:20,607 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 17:47:20,608 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-02-02 17:47:20,612 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 253 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 17:47:20,614 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 257 bytes from disk\n",
      "2020-02-02 17:47:20,624 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 17:47:20,625 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 17:47:20,629 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-02-02 17:47:20,630 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 17:47:20,648 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:20,650 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:20,658 [pool-4-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-02-02 17:47:20,748 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local173023042_0001_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 17:47:20,761 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 17:47:20,762 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local173023042_0001_r_000000_0 is allowed to commit now\n",
      "2020-02-02 17:47:20,773 [pool-4-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local173023042_0001_r_000000_0' to file:/tmp/temp-431605845/tmp-1441524042/_temporary/0/task_local173023042_0001_r_000000\n",
      "2020-02-02 17:47:20,776 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 17:47:20,776 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local173023042_0001_r_000000_0' done.\n",
      "2020-02-02 17:47:20,786 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local173023042_0001_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5805945\n",
      "\t\tFILE: Number of bytes written=12075224\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=257\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=237502464\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 17:47:20,795 [pool-4-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local173023042_0001_r_000000_0\n",
      "2020-02-02 17:47:20,796 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 17:47:24,448 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:24,477 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:24,478 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-02-02 17:47:24,481 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:24,716 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:24,749 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-02 17:47:24,866 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-02 17:47:24,873 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-02 17:47:24,929 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1914903828_0002\n",
      "2020-02-02 17:47:25,256 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665645025/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:25,264 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665645025/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:25,265 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665645025/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:25,265 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp-1671287885/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580665645025/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:25,266 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665645026/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:25,273 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665645026/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:25,273 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665645026/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:25,273 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp1672617601/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580665645026/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:25,276 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665645027/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:25,283 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665645027/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:25,284 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665645027/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:25,284 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp-368537368/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580665645027/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:25,286 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580665645028/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:25,295 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580665645028/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-02-02 17:47:25,295 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580665645028/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:25,295 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp-431605845/tmp1615340480/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580665645028/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:25,392 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665645025/pig-0.17.0-core-h2.jar\n",
      "2020-02-02 17:47:25,393 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665645026/automaton-1.11-8.jar\n",
      "2020-02-02 17:47:25,393 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665645027/antlr-runtime-3.4.jar\n",
      "2020-02-02 17:47:25,393 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580665645028/joda-time-2.9.3.jar\n",
      "2020-02-02 17:47:25,395 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-02-02 17:47:25,405 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-02-02 17:47:25,462 [Thread-54] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-02 17:47:25,466 [Thread-54] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-02 17:47:25,466 [Thread-54] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-02 17:47:25,467 [Thread-54] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:25,468 [Thread-54] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:25,471 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-02-02 17:47:25,501 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-02-02 17:47:25,501 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1914903828_0002_m_000000_0\n",
      "2020-02-02 17:47:25,543 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:25,543 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:25,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 17:47:25,553 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 211\n",
      "Input split[0]:\n",
      "   Length = 211\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-02-02 17:47:25,618 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-02-02 17:47:25,619 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-02-02 17:47:25,619 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-02-02 17:47:25,619 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-02-02 17:47:25,620 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-02-02 17:47:25,622 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-02-02 17:47:25,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-02-02 17:47:25,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-02-02 17:47:25,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-02-02 17:47:25,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 231; bufvoid = 104857600\n",
      "2020-02-02 17:47:25,638 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214360(104857440); length = 37/6553600\n",
      "2020-02-02 17:47:25,641 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-02-02 17:47:25,645 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1914903828_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 17:47:25,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-02-02 17:47:25,665 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1914903828_0002_m_000000_0' done.\n",
      "2020-02-02 17:47:25,666 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1914903828_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11607432\n",
      "\t\tFILE: Number of bytes written=24156959\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=10\n",
      "\t\tMap output records=10\n",
      "\t\tMap output bytes=231\n",
      "\t\tMap output materialized bytes=257\n",
      "\t\tInput split bytes=379\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=10\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=323485696\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-02-02 17:47:25,667 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1914903828_0002_m_000000_0\n",
      "2020-02-02 17:47:25,667 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-02-02 17:47:25,669 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-02-02 17:47:25,670 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1914903828_0002_r_000000_0\n",
      "2020-02-02 17:47:25,706 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:25,707 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:25,710 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-02-02 17:47:25,710 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@148d3c46\n",
      "2020-02-02 17:47:25,711 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-02-02 17:47:25,713 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1914903828_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-02-02 17:47:25,725 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1914903828_0002_m_000000_0 decomp: 253 len: 257 to MEMORY\n",
      "2020-02-02 17:47:25,730 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 253 bytes from map-output for attempt_local1914903828_0002_m_000000_0\n",
      "2020-02-02 17:47:25,731 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 253, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->253\n",
      "2020-02-02 17:47:25,733 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-02-02 17:47:25,735 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 17:47:25,736 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-02-02 17:47:25,739 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 17:47:25,746 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-02-02 17:47:25,739 [Readahead Thread #2] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-02-02 17:47:25,754 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 253 bytes to disk to satisfy reduce memory limit\n",
      "2020-02-02 17:47:25,755 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 257 bytes from disk\n",
      "2020-02-02 17:47:25,755 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-02-02 17:47:25,755 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-02-02 17:47:25,761 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 231 bytes\n",
      "2020-02-02 17:47:25,763 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 17:47:25,770 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-02-02 17:47:25,771 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-02-02 17:47:25,898 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1914903828_0002_r_000000_0 is done. And is in the process of committing\n",
      "2020-02-02 17:47:25,919 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-02-02 17:47:25,920 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1914903828_0002_r_000000_0 is allowed to commit now\n",
      "2020-02-02 17:47:26,172 [pool-9-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1914903828_0002_r_000000_0' to file:/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q04-10/output/_temporary/0/task_local1914903828_0002_r_000000\n",
      "2020-02-02 17:47:26,175 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-02-02 17:47:26,175 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1914903828_0002_r_000000_0' done.\n",
      "2020-02-02 17:47:26,176 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1914903828_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11607978\n",
      "\t\tFILE: Number of bytes written=24157369\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=10\n",
      "\t\tReduce shuffle bytes=257\n",
      "\t\tReduce input records=10\n",
      "\t\tReduce output records=10\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=323485696\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-02-02 17:47:26,176 [pool-9-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1914903828_0002_r_000000_0\n",
      "2020-02-02 17:47:26,177 [Thread-54] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-02-02 17:47:30,423 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,426 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,428 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,459 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,461 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,463 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,479 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,482 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-02-02 17:47:30,485 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
