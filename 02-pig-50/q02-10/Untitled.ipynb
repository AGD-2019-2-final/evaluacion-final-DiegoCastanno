{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-26 23:07:04,541 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address\n",
      "2020-01-26 23:07:05,326 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-26 23:07:05,655 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - session.id is deprecated. Instead, use dfs.metrics.session-id\n",
      "2020-01-26 23:07:05,656 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Initializing JVM Metrics with processName=JobTracker, sessionId=\n",
      "2020-01-26 23:07:05,682 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-26 23:07:05,685 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-01-26 23:07:05,696 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-01-26 23:07:05,791 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-01-26 23:07:05,802 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:05,815 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-01-26 23:07:05,868 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-26 23:07:05,953 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-26 23:07:05,979 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-26 23:07:06,081 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local53259476_0001\n",
      "2020-01-26 23:07:06,372 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080026175/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:06,382 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080026175/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:06,382 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080026175/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:06,383 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-170823595/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580080026175/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:06,401 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080026176/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:06,411 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080026176/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:06,411 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080026176/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:06,411 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp670226293/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580080026176/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:06,412 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080026177/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:06,428 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080026177/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:06,428 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080026177/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:06,429 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp1064586710/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580080026177/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:06,435 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080026178/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:06,441 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080026178/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:06,442 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080026178/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:06,442 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp1339315371/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580080026178/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:06,504 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080026175/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:06,504 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080026176/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:06,505 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080026177/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:06,505 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080026178/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:06,515 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-26 23:07:06,521 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-26 23:07:06,563 [Thread-14] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-26 23:07:06,568 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:06,568 [Thread-14] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:06,569 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-26 23:07:06,641 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-26 23:07:06,642 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local53259476_0001_m_000000_0\n",
      "2020-01-26 23:07:06,701 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:06,701 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:06,734 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-26 23:07:06,747 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 244\n",
      "Input split[0]:\n",
      "   Length = 244\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-26 23:07:06,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:06,773 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:06,825 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-26 23:07:06,826 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local53259476_0001_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-26 23:07:06,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-26 23:07:06,838 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task attempt_local53259476_0001_m_000000_0 is allowed to commit now\n",
      "2020-01-26 23:07:06,842 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local53259476_0001_m_000000_0' to file:/tmp/temp693229094/tmp185280314/_temporary/0/task_local53259476_0001_m_000000\n",
      "2020-01-26 23:07:06,845 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-26 23:07:06,845 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local53259476_0001_m_000000_0' done.\n",
      "2020-01-26 23:07:06,852 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local53259476_0001_m_000000_0: Counters: 15\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=5801523\n",
      "\t\tFILE: Number of bytes written=12061177\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=15\n",
      "\t\tMap output records=15\n",
      "\t\tInput split bytes=398\n",
      "\t\tSpilled Records=0\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=176685056\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-26 23:07:06,853 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local53259476_0001_m_000000_0\n",
      "2020-01-26 23:07:06,853 [Thread-14] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-26 23:07:11,545 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:11,560 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:11,561 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.map.tasks is deprecated. Instead, use mapreduce.job.maps\n",
      "2020-01-26 23:07:11,561 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-26 23:07:11,562 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:11,641 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:11,656 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-26 23:07:11,779 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-26 23:07:11,782 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-26 23:07:11,799 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local739662446_0002\n",
      "2020-01-26 23:07:11,985 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080031835/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:11,991 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080031835/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:11,991 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080031835/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:11,991 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-461669004/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580080031835/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:11,992 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080031836/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:12,003 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080031836/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:12,004 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080031836/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:12,004 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-723453179/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580080031836/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:12,005 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080031837/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:12,015 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080031837/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:12,016 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080031837/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:12,016 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-709611686/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580080031837/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:12,018 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080031838/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:12,031 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080031838/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:12,031 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080031838/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:12,031 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-134677289/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580080031838/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:12,073 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080031835/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:12,074 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080031836/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:12,074 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080031837/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:12,075 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080031838/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:12,079 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-26 23:07:12,080 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-26 23:07:12,093 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-26 23:07:12,093 [Thread-48] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-26 23:07:12,093 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:12,093 [Thread-48] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:12,093 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-26 23:07:12,099 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-26 23:07:12,100 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local739662446_0002_m_000000_0\n",
      "2020-01-26 23:07:12,132 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:12,132 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:12,133 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-26 23:07:12,136 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 344\n",
      "Input split[0]:\n",
      "   Length = 344\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-26 23:07:12,185 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-26 23:07:12,185 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-26 23:07:12,185 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-26 23:07:12,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-26 23:07:12,188 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-26 23:07:12,199 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-26 23:07:12,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-26 23:07:12,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-26 23:07:12,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-26 23:07:12,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 373; bufvoid = 104857600\n",
      "2020-01-26 23:07:12,245 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600\n",
      "2020-01-26 23:07:12,254 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-26 23:07:12,258 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local739662446_0002_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-26 23:07:12,267 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-26 23:07:12,267 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local739662446_0002_m_000000_0' done.\n",
      "2020-01-26 23:07:12,268 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local739662446_0002_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603141\n",
      "\t\tFILE: Number of bytes written=24142082\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=15\n",
      "\t\tMap output records=15\n",
      "\t\tMap output bytes=373\n",
      "\t\tMap output materialized bytes=409\n",
      "\t\tInput split bytes=376\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=15\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=195559424\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-26 23:07:12,268 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local739662446_0002_m_000000_0\n",
      "2020-01-26 23:07:12,269 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-26 23:07:12,274 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-26 23:07:12,274 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local739662446_0002_r_000000_0\n",
      "2020-01-26 23:07:12,289 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:12,290 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:12,292 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-26 23:07:12,295 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2351e358\n",
      "2020-01-26 23:07:12,313 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-26 23:07:12,315 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local739662446_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-26 23:07:12,500 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#1 about to shuffle output of map attempt_local739662446_0002_m_000000_0 decomp: 405 len: 409 to MEMORY\n",
      "2020-01-26 23:07:12,505 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 405 bytes from map-output for attempt_local739662446_0002_m_000000_0\n",
      "2020-01-26 23:07:12,507 [localfetcher#1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 405, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->405\n",
      "2020-01-26 23:07:12,513 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-26 23:07:12,514 [Readahead Thread #0] WARN  org.apache.hadoop.io.ReadaheadPool - Failed readahead on ifile\n",
      "EBADF: Bad file descriptor\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)\n",
      "\tat org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)\n",
      "\tat org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:208)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "2020-01-26 23:07:12,514 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-26 23:07:12,522 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-26 23:07:12,530 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-26 23:07:12,530 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 388 bytes\n",
      "2020-01-26 23:07:12,535 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 405 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-26 23:07:12,536 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 409 bytes from disk\n",
      "2020-01-26 23:07:12,537 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-26 23:07:12,537 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-26 23:07:12,538 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 388 bytes\n",
      "2020-01-26 23:07:12,538 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-26 23:07:12,548 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:12,548 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:12,551 [pool-6-thread-1] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords\n",
      "2020-01-26 23:07:12,583 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local739662446_0002_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-26 23:07:12,592 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-26 23:07:12,592 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local739662446_0002_r_000000_0 is allowed to commit now\n",
      "2020-01-26 23:07:12,595 [pool-6-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local739662446_0002_r_000000_0' to file:/tmp/temp693229094/tmp-1721410357/_temporary/0/task_local739662446_0002_r_000000\n",
      "2020-01-26 23:07:12,598 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-26 23:07:12,598 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local739662446_0002_r_000000_0' done.\n",
      "2020-01-26 23:07:12,601 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local739662446_0002_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=11603991\n",
      "\t\tFILE: Number of bytes written=24142557\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=1\n",
      "\t\tReduce shuffle bytes=409\n",
      "\t\tReduce input records=15\n",
      "\t\tReduce output records=1\n",
      "\t\tSpilled Records=15\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=127\n",
      "\t\tTotal committed heap usage (bytes)=379584512\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-26 23:07:12,604 [pool-6-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local739662446_0002_r_000000_0\n",
      "2020-01-26 23:07:12,605 [Thread-48] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-26 23:07:17,160 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:17,162 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:17,165 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:17,225 [JobControl] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:17,241 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-01-26 23:07:17,303 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-01-26 23:07:17,305 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-01-26 23:07:17,313 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_local1712328914_0003\n",
      "2020-01-26 23:07:17,444 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080037342/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:17,448 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080037342/pig-0.17.0-core-h2.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:17,448 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080037342/pig-0.17.0-core-h2.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:17,448 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp1965783030/pig-0.17.0-core-h2.jar as file:/tmp/hadoop-root/mapred/local/1580080037342/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:17,449 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080037343/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:17,453 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080037343/automaton-1.11-8.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:17,453 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080037343/automaton-1.11-8.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:17,453 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp1414348248/automaton-1.11-8.jar as file:/tmp/hadoop-root/mapred/local/1580080037343/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:17,455 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080037344/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:17,466 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080037344/antlr-runtime-3.4.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:17,466 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080037344/antlr-runtime-3.4.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:17,466 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-1023066412/antlr-runtime-3.4.jar as file:/tmp/hadoop-root/mapred/local/1580080037344/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:17,467 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080037345/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:17,471 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080037345/joda-time-2.9.3.jar /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar': Protocol error\n",
      "\n",
      "2020-01-26 23:07:17,471 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080037345/joda-time-2.9.3.jar <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:17,471 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp1282847206/joda-time-2.9.3.jar as file:/tmp/hadoop-root/mapred/local/1580080037345/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:17,472 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Creating symlink: /tmp/hadoop-root/mapred/local/1580080037346/tmp-1721410357 <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pigsample_2020602315_1580080037212\n",
      "2020-01-26 23:07:17,476 [JobControl] WARN  org.apache.hadoop.fs.FileUtil - Command 'ln -s /tmp/hadoop-root/mapred/local/1580080037346/tmp-1721410357 /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pigsample_2020602315_1580080037212' failed 1 with: ln: failed to create symbolic link '/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pigsample_2020602315_1580080037212': Protocol error\n",
      "\n",
      "2020-01-26 23:07:17,476 [JobControl] WARN  org.apache.hadoop.mapred.LocalDistributedCacheManager - Failed to create symlink: /tmp/hadoop-root/mapred/local/1580080037346/tmp-1721410357 <- /datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/pigsample_2020602315_1580080037212\n",
      "2020-01-26 23:07:17,476 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - Localized file:/tmp/temp693229094/tmp-1721410357 as file:/tmp/hadoop-root/mapred/local/1580080037346/tmp-1721410357\n",
      "2020-01-26 23:07:17,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080037342/pig-0.17.0-core-h2.jar\n",
      "2020-01-26 23:07:17,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080037343/automaton-1.11-8.jar\n",
      "2020-01-26 23:07:17,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080037344/antlr-runtime-3.4.jar\n",
      "2020-01-26 23:07:17,517 [JobControl] INFO  org.apache.hadoop.mapred.LocalDistributedCacheManager - file:/tmp/hadoop-root/mapred/local/1580080037345/joda-time-2.9.3.jar\n",
      "2020-01-26 23:07:17,518 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://localhost:8080/\n",
      "2020-01-26 23:07:17,518 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter set in config null\n",
      "2020-01-26 23:07:17,526 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-01-26 23:07:17,527 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-01-26 23:07:17,527 [Thread-87] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-01-26 23:07:17,528 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:17,528 [Thread-87] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:17,528 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - OutputCommitter is org.apache.pig.backend.hadoop.executionengine.mapReduceLayer.PigOutputCommitter\n",
      "2020-01-26 23:07:17,544 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for map tasks\n",
      "2020-01-26 23:07:17,544 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1712328914_0003_m_000000_0\n",
      "2020-01-26 23:07:17,558 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:17,558 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:17,558 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-26 23:07:17,560 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Processing split: Number of splits :1\n",
      "Total Length = 344\n",
      "Input split[0]:\n",
      "   Length = 344\n",
      "   ClassName: org.apache.hadoop.mapreduce.lib.input.FileSplit\n",
      "   Locations:\n",
      "\n",
      "-----------------------\n",
      "\n",
      "2020-01-26 23:07:17,656 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - (EQUATOR) 0 kvi 26214396(104857584)\n",
      "2020-01-26 23:07:17,656 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - mapreduce.task.io.sort.mb: 100\n",
      "2020-01-26 23:07:17,656 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - soft limit at 83886080\n",
      "2020-01-26 23:07:17,656 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufvoid = 104857600\n",
      "2020-01-26 23:07:17,656 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396; length = 6553600\n",
      "2020-01-26 23:07:17,658 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer\n",
      "2020-01-26 23:07:17,663 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - \n",
      "2020-01-26 23:07:17,663 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Starting flush of map output\n",
      "2020-01-26 23:07:17,663 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Spilling map output\n",
      "2020-01-26 23:07:17,663 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - bufstart = 0; bufend = 374; bufvoid = 104857600\n",
      "2020-01-26 23:07:17,663 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - kvstart = 26214396(104857584); kvend = 26214340(104857360); length = 57/6553600\n",
      "2020-01-26 23:07:17,664 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.MapTask - Finished spill 0\n",
      "2020-01-26 23:07:17,669 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1712328914_0003_m_000000_0 is done. And is in the process of committing\n",
      "2020-01-26 23:07:17,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - map\n",
      "2020-01-26 23:07:17,673 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1712328914_0003_m_000000_0' done.\n",
      "2020-01-26 23:07:17,674 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1712328914_0003_m_000000_0: Counters: 17\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17405691\n",
      "\t\tFILE: Number of bytes written=36221067\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=15\n",
      "\t\tMap output records=15\n",
      "\t\tMap output bytes=374\n",
      "\t\tMap output materialized bytes=410\n",
      "\t\tInput split bytes=376\n",
      "\t\tCombine input records=0\n",
      "\t\tSpilled Records=15\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=0\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=484966400\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=0\n",
      "2020-01-26 23:07:17,674 [LocalJobRunner Map Task Executor #0] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1712328914_0003_m_000000_0\n",
      "2020-01-26 23:07:17,674 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - map task executor complete.\n",
      "2020-01-26 23:07:17,682 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - Waiting for reduce tasks\n",
      "2020-01-26 23:07:17,683 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Starting task: attempt_local1712328914_0003_r_000000_0\n",
      "2020-01-26 23:07:17,698 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:17,698 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:17,699 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task -  Using ResourceCalculatorProcessTree : [ ]\n",
      "2020-01-26 23:07:17,700 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.ReduceTask - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2e1eb505\n",
      "2020-01-26 23:07:17,700 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - MergerManager: memoryLimit=652528832, maxSingleShuffleLimit=163132208, mergeThreshold=430669056, ioSortFactor=10, memToMemMergeOutputsThreshold=10\n",
      "2020-01-26 23:07:17,707 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - attempt_local1712328914_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events\n",
      "2020-01-26 23:07:17,709 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.LocalFetcher - localfetcher#2 about to shuffle output of map attempt_local1712328914_0003_m_000000_0 decomp: 406 len: 410 to MEMORY\n",
      "2020-01-26 23:07:17,710 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.InMemoryMapOutput - Read 406 bytes from map-output for attempt_local1712328914_0003_m_000000_0\n",
      "2020-01-26 23:07:17,715 [localfetcher#2] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - closeInMemoryFile -> map-output of size: 406, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->406\n",
      "2020-01-26 23:07:17,715 [EventFetcher for fetching Map Completion Events] INFO  org.apache.hadoop.mapreduce.task.reduce.EventFetcher - EventFetcher is interrupted.. Returning\n",
      "2020-01-26 23:07:17,716 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-26 23:07:17,717 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs\n",
      "2020-01-26 23:07:17,719 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-26 23:07:17,720 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 396 bytes\n",
      "2020-01-26 23:07:17,723 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merged 1 segments, 406 bytes to disk to satisfy reduce memory limit\n",
      "2020-01-26 23:07:17,723 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 1 files, 410 bytes from disk\n",
      "2020-01-26 23:07:17,723 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.task.reduce.MergeManagerImpl - Merging 0 segments, 0 bytes from memory into reduce\n",
      "2020-01-26 23:07:17,724 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Merging 1 sorted segments\n",
      "2020-01-26 23:07:17,728 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Merger - Down to the last merge-pass, with 1 segments left of total size: 396 bytes\n",
      "2020-01-26 23:07:17,728 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-26 23:07:17,731 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - File Output Committer Algorithm version is 1\n",
      "2020-01-26 23:07:17,732 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\n",
      "2020-01-26 23:07:17,805 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task:attempt_local1712328914_0003_r_000000_0 is done. And is in the process of committing\n",
      "2020-01-26 23:07:17,814 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - 1 / 1 copied.\n",
      "2020-01-26 23:07:17,815 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task attempt_local1712328914_0003_r_000000_0 is allowed to commit now\n",
      "2020-01-26 23:07:17,837 [pool-11-thread-1] INFO  org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter - Saved output of task 'attempt_local1712328914_0003_r_000000_0' to file:/datalake/evaluacion-final-DiegoCastanno/02-pig-50/q02-10/output/_temporary/0/task_local1712328914_0003_r_000000\n",
      "2020-01-26 23:07:17,838 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce > reduce\n",
      "2020-01-26 23:07:17,838 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Task 'attempt_local1712328914_0003_r_000000_0' done.\n",
      "2020-01-26 23:07:17,838 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.Task - Final Counters for attempt_local1712328914_0003_r_000000_0: Counters: 24\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=17406543\n",
      "\t\tFILE: Number of bytes written=36221720\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\tMap-Reduce Framework\n",
      "\t\tCombine input records=0\n",
      "\t\tCombine output records=0\n",
      "\t\tReduce input groups=15\n",
      "\t\tReduce shuffle bytes=410\n",
      "\t\tReduce input records=15\n",
      "\t\tReduce output records=15\n",
      "\t\tSpilled Records=15\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=0\n",
      "\t\tTotal committed heap usage (bytes)=484966400\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=0\n",
      "2020-01-26 23:07:17,838 [pool-11-thread-1] INFO  org.apache.hadoop.mapred.LocalJobRunner - Finishing task: attempt_local1712328914_0003_r_000000_0\n",
      "2020-01-26 23:07:17,838 [Thread-87] INFO  org.apache.hadoop.mapred.LocalJobRunner - reduce task executor complete.\n",
      "2020-01-26 23:07:22,744 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,746 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,748 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,770 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,771 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,772 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,786 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,788 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,789 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,798 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,799 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n",
      "2020-01-26 23:07:22,799 [main] INFO  org.apache.hadoop.metrics.jvm.JvmMetrics - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized\n"
     ]
    }
   ],
   "source": [
    "!python3 grader.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
